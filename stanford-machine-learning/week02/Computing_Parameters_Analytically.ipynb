{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 - Notes\n",
    "---\n",
    "\n",
    "## Computing parameters analytically - The Normal equation\n",
    "\n",
    "**Normal equation:** Method to solve for &theta; analytically, in a single step.\n",
    "\n",
    "The normal equation has some advantages and some disadvantages when compared to gradient descent.\n",
    "\n",
    "**How does it work:** Instead of performing gradient descent, we perform the minimization explicitly by taking each partial derivative with respect to the &theta;<sub>j</sub>'s, and setting them to zero, all without resorting to an iterative algorithm. The formal for the value of &theta; that minimizes the cost function is given below:\n",
    "\n",
    "### &theta; = (X<sup>T</sup>X)<sup>-1</sup>X<sup>T</sup>y\n",
    "\n",
    "Feature scaling is not necessary when using the normal equation.\n",
    "\n",
    "## Gradient descent vs. Normal equation\n",
    "\n",
    "With m training examples, and n features\n",
    "\n",
    "### Gradient descent - O(kn<sup>2</sup>)\n",
    "**Advantages**\n",
    "* Works well when n is large (even when n >= 10<sup>6</sup>)\n",
    "\n",
    "**Disadvantages**\n",
    "* Need to choose learning rate a\n",
    "* Needs many iterations\n",
    "\n",
    "### Normal equation - O(n<sup>3</sup>)\n",
    "**Advantages**\n",
    "* No need to choose learning rate alpha\n",
    "* No need to run multiple iterations\n",
    "\n",
    "**Disadvantages**\n",
    "* Need to compute (X<sup>T</sup>X)<sup>-1</sup>, an nxn matrix, which is very expensive, on the order of O(n<sup>3</sup>). If n is sufficiently large (n >= 10,000), the normal equation will operate significantly slower than gradient descent.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "\n",
    "# Python implementation of the normal equation for computing the minimum\n",
    "# of a cost function J([theta_0, theta_1, ... theta_n])\n",
    "# Input: (x, y) training set\n",
    "# Output: [theta_0, theta_1, ... theta_n] such that J([theta]) is at a minimum\n",
    "def normal_equation(x, y):\n",
    "    X = np.matrix(x)\n",
    "    Y = np.matrix(y).transpose()\n",
    "    return np.matmul(np.matmul(inv(np.matmul(X.transpose(), X)), X.transpose()), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.09474484]\n",
      " [0.19123063]]\n"
     ]
    }
   ],
   "source": [
    "# Testing the normal equation\n",
    "\n",
    "x = [\n",
    "    [3.9,8.94],\n",
    "    [5.4,10.85],\n",
    "    [5.8,11.61],\n",
    "    [6,13.65],\n",
    "    [6.5,13.54],\n",
    "    [6.1,13.29],\n",
    "    [5.9,17.65],\n",
    "    [5.5,18.81],\n",
    "    [5.4,17.91]\n",
    "  ]\n",
    "y = [8.73,14.28,17.68,9.94,14.99,18.75,11.4,15.08,19.3]\n",
    "\n",
    "print(normal_equation(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Non-invertible matrices\n",
    "\n",
    "**What if X<sup>T</sup>X is non-invertible (singular/degenerate)?**\n",
    "* _When would this occur? -_ X is **singular/degenerate** if X is a square matrix with a determinant = 0 (**_determinant_**: A = \\[\\[a b\\], \\[c d\\]\\], |A| = ad - bc). This is rare because a square matrix randomly selected from a continuous uniform distribution will almost never have a determinant = 0\n",
    "* _Why would this occur? -_ This may occur when you have redundant features in the learning problem (linearly dependent features). E.g. If your features are linearly dependent, such as: x<sub>1</sub> = size in feet<sup>2</sup>, x<sub>2</sub> = size in meters<sup>2</sup>.\n",
    "* This may also occur when you have too many features (e,g, m <= n, when you have more features than samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
